# 📋 Feature Engineering for Dating Dataset

본 프로젝트는 speed dating 데이터셋을 기반으로

전처리 및 피처 엔지니어링을 통해 단순 수집된 정보를 넘어서 변수 간의 관계와 의미를 확장한 새로운 피처를 설계하고, 이를 함수화하여 재활용 가능한 코드로 패키징하는 것을 목표로 합니다.

> 🛠️ 사용 환경: Python, Pandas, Jupyter Notebook

<br>
<br>

프로젝트는 아래의 두 단계로 나누어 진행하였습니다.

1. **피처 엔지니어링**
    
    ✓ &nbsp;`feature-engineering-dating.ipynb` 파일에서 다양한 전처리 및 변수 변환 기법을 활용하여 피처 엔지니어링 수행
    
2. **모듈화 및 패키징**
    
    ✓ &nbsp;실습에 사용된 주요 전처리 로직들을 함수로 분리하여 `.py` 파일로 모듈화  
    ✓ &nbsp;`src/` 디렉토리에 저장한 후, 해당 함수들을 불러와 동일한 실습을 함수 기반으로 재현  
    ✓ &nbsp;이를 통해 코드의 재사용성과 유지 보수성을 높이는 과정을 경험

> 모듈화 및 패키징의 자세한 구현 과정은 [velog.io/@jul-ee](https://velog.io/@jul-ee/DS-%EB%B9%84%EC%A0%95%EC%A0%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%AA%A8%EB%93%88%ED%99%94%EC%99%80-%ED%8C%A8%ED%82%A4%EC%A7%95%EC%9C%BC%EB%A1%9C-%EC%A0%84%EC%B2%98%EB%A6%AC-%EC%9E%90%EB%8F%99%ED%99%94%ED%95%98%EA%B8%B0)에서 확인할 수 있습니다.

<br>
<br>


## 📂 사용 데이터셋

본 프로젝트에서 사용된 데이터는 소개팅(Speed Dating) 데이터셋으로

한 사람(A)이 여러 명의 이성(B)들과 짧은 시간 동안 대화를 나눈 뒤, 서로에 대한 평가를 남긴 결과를 수집한 설문 기반 데이터이다.

이 데이터는 참가자가 중요하게 생각하는 특성, 실제 상대에 대한 평가 점수, 그리고 최종적으로 매칭이 성사되었는지를 나타내는 결과 컬럼 등으로 구성되어 있다.

- 각 행(row)은 "한 사람(A)이 특정 상대방(B)과 대화한 결과"를 나타낸다.
- 동일한 참가자가 여러 상대와 대화한 결과가 각각 행(row)으로 존재하므로, 한 사람의 데이터가 여러 줄에 걸쳐 등장한다.

> 예측 목표(종속변수)는 match 컬럼이며, 이를 기반으로 상대방과의 매칭 여부를 예측하는 모델을 구성할 수 있다.
> 

<br>

### 주요 컬럼

| 그룹 | 예시 컬럼 | 설명 |
| --- | --- | --- |
| 참가자 정보 | `gender`, `age`, `race` | 참가자 본인의 성별, 나이, 인종 |
| 파트너 정보 | `age_o`, `race_o` | 파트너의 성별, 나이, 인종 |
| 중요도 (가중치) | `pref_o_*`, `*_important` | 이성에게 중요하다고 생각하는 특성에 대한 가중치 (총합 100) |
| 파트너 평가 점수 | `o_*` | 참가자에 대해 파트너가 준 평가 점수 (1~10) |
| 참가자 평가 점수 | `*_partner` | 파트너에 대해 참가자가 준 평가 점수 (1~10) |
| 기타 지표 | `interests_correlate`, `like`, `guess_prob_liked` 등 | 취향 유사도, 만족도 예측, 기대 지표 등 |
| 예측 대상 | `match` | 실제 매칭 여부 (1: 매칭됨, 0: 매칭되지 않음) |

<br>

### 6가지 주요 평가 항목 (중요도 및 평가 점수)

- `attractive`: &nbsp;외모/매력
- `sincere`: &nbsp;진심/성격
- `intelligence`: &nbsp;지능/똑똑함
- `funny`: &nbsp;유머감각
- `ambition`: &nbsp;목표/야망
- `shared_interests`: &nbsp;취미/관심사 유사도

<br>

### 데이터 특징 요약

- `pref_o_*` 컬럼들의 합은 반드시 100이어야 함 &nbsp;→ 가중치 비율 정규화 필요
- 일부 평가 점수(`_o`)에 10을 초과하는 비정상 값(예: 10.5, 11) 존재 &nbsp;→ 정제 필요
- `interests_correlate`는 1 ~ 1 범위의 상관계수 개념 &nbsp;→ 연속형 변수로 해석
- 동일 참가자 ID는 없지만 한 사람이 여러 줄로 중복 등장함 &nbsp;→ 분석 시 주의 필요
- 예측 대상 컬럼 `match`는 **분류 모델의 Target** &nbsp;→ 결측치 제거 필요

<br>
<br>

## 📁 디렉토리 구조

```
feature-engineering-dating/
├── feature-engineering-dating.ipynb     # 피처 엔지니어링 실습 노트북
├── .gitignore
├── README.md
└── src/                                 # 전처리 함수 모듈
    ├── code_function_dating.ipynb       # 함수화된 전처리 흐름을 재구성한 노트북
    ├── col_rename.py                    # 컬럼명 통일을 위한 일괄 변경
    ├── missing_func.py                  # 결측치 제거 및 -99 보정
    ├── outlier_func.py                  # 점수 이상치 제거
    ├── imp_func.py                      # 중요도 합 100으로 정규화
    ├── age_gap_func.py                  # 나이 차이 및 방향성 파생 변수 생성
    ├── race_func.py                     # 인종 일치 여부 및 중요도 가중치 적용
    ├── rating_func.py                   # 항목별 조화평균으로 평가 점수 계산
    ├── sel_one_func.py                  # 모델링을 위한 원-핫 인코딩 및 컬럼 선택
    ├── pre_func.py                      # 전체 전처리 파이프라인 통합
    └── ...

```

<br>
<br>

## 분석 프로세스

[1] &nbsp;컬럼명 정리 및 통일

- `pref_o_`, `attractive_o` 등 통일성이 부족한 컬럼명을 `o_important_`, `i_score_`와 같은 구조로 일관되게 재정의

  → &nbsp;변수 그룹(상대 평가/본인 평가/중요도 등)을 명확히 구분하여 후속 처리와 시각화, 분석의 확장성과 가독성을 높이기 위함

<br>

[2] &nbsp;결측치 및 무응답 처리
- 6가지 주요 평가 항목 중 2개 이상 누락된 항목이 발견되어 drop하는 방향으로 처리
- 일부 항목의 결측치는 -99로 처리하여 무응답 정보를 유지

  → &nbsp;응답 누락이 단순 결측이라기보다 참가자 성향의 일부일 수 있으므로, 무작정 제거하지 않고 분석 가능한 형태로 변환

<br>

[3] &nbsp;Feature Engineering - 중요도 비율화
- 6가지 주요 평가 항목의 합이 100이 되지 않는 경우, 총합을 기준으로 비율을 재계산하여 정규화된 가중치 반영

  → &nbsp;합이 100은 아니어도 사용자 의도가 담긴 상대적 중요도는 유의미하다고 보고  
  → &nbsp;정규화된 비중을 기반으로 모델이 각 항목의 중요도를 학습할 수 있게 하기 위함

<br>

[4] &nbsp;Feature Engineering - Age
- 두 성별 간의 '나이차'를 계산 후 결측치를 -99로 유지하여 파생 변수에도 반영

  → &nbsp;단순한 수치보다도 나이 차이의 방향성(남성이 많음/여성이 많음)도 관계 형성에 영향을 줄 수 있기 때문에 이를 별도의 컬럼으로 생성

<br>

[5] &nbsp;Feature Engineering - Race
- 참가자와 상대방의 인종이 같은지 여부를 same_race 변수로 생성

- 인종이 다를 경우 `same_race = -1`로 처리하여 차이를 명확히 표현

  → &nbsp;단순히 같은지 여부만 보는 것보다, 중요도(`importance_same_race`)에 따라 의미가 달라질 수 있기 때문

<br>

[6] &nbsp;Feature Engineering - Rating
-  i_rating_total, o_rating_total, 그리고 두 값을 활용한 조화 평균(rating_mean) 계산
  → &nbsp;`rating_mean = 2 * (o_rating * i_rating) / (o_rating + i_rating)`

- `o_important`가 0인 항목은 평균 산출에서 제외하기 위해 -99로 처리

  → &nbsp;평가 항목별로 중요도와 점수 간의 불균형을 보정하기 위함
  
  → &nbsp;조화 평균은 두 값이 모두 높을 때 가장 높게 나타나는 특성이 있어, 매칭 예측력 향상에 적합한 변수로 판단

<br>

[7] &nbsp;모듈화 및 패키징
- 전처리 단계별 로직을 함수로 분리하여 코드 재사용 가능하도록 구조화

  →  &nbsp;실습의 목적이었던 구조적 피처 엔지니어링의 재현 가능성 확보를 위해, 같은 로직을 반복 재사용할 수 있도록 설계된 파이프라인 방식으로 정리



<br>
<br>

## 💡 인사이트 및 결론

- 결측치, 이상치 외에도 각각의 행이 지니는 의미도 충분히 이해해야 한다.

  →  &nbsp;해당 데이터셋에서는 본인을 판별하는 ID 등의 정보가 없기 때문에 데이터를 더 들여다보고 이해해야 한다.

- 종속변수 컬럼에 결측치가 있는 경우 평균이나 임의의 값으로 채울 수 없고 drop 시켜야 한다.

  →  &nbsp;match 등의 종속변수는 예측해야 하는 일종의 정답이므로 틀어져 버리면 노이즈 그 이상으로 잘못된 예측이 될 수 있다.


- 가중치 재정규화에서는 총합이 100이라는 조건을 만족시키기 위한 비율 계산이 필요하며, 이는 변수 간 중요도 해석에 직접적인 영향을 주기 때문에 데이터 신뢰도를 높이는 핵심 작업이다.
    
- 이후 어떤 머신러닝 알고리즘을 사용할 것인가에 따라 스케일링 단계를 고려해야 한다.

  →  해당 데이터에서는 트리 모델이 가장 적합한데, 그렇다면 스케일링이 크게 중요하지 않으므로 스케일링 과정은 생략하였다.

- 평가 점수 계산이나 결측치 처리 로직처럼 조건 기반의 연산이 반복적으로 사용되는 경우,
    
  →  &nbsp;노트북에서 일일이 작성하던 로직을 함수로 빼둠으로써 훨씬 효율적이고 실용적으로 처리할 수 있다.

- 함수화를 통해 전처리 과정을 구조화한 경험을 통해 유사한 문제 해결에서 재사용 가능성과 유지 보수 편의성을 높일 수 있는 인사이트를 얻을 수 있었다.
    

<br>

> 본 프로젝트는 Feature Engineering을 포함한 전처리 프로세스를 체계적으로 정리하고, 이를 구조화하여 다시 적용해보는 과정을 통해 전처리의 중요성과 모듈화의 필요성을 학습하는 데 중점을 두었습니다.

<br>
